{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ac147a",
   "metadata": {},
   "source": [
    "# 라이브러리 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f30b48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 파일 처리\n",
    "import os\n",
    "\n",
    "# Data 처리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ML, DNN, CNN 관련 라이브러리\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Input, GlobalAveragePooling2D, Softmax\n",
    "\n",
    "import efficientnet.tfkeras as efn\n",
    "import math\n",
    "##############################################################\n",
    "\n",
    "# 이미지 및 그래프 출력\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# 해쉬(phash) 값 처리\n",
    "import imagehash\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# Text Data NLP 처리\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('popular')\n",
    "\n",
    "from shutil import copyfile\n",
    "#copyfile(src = \"./tokenization.py\", dst = \"./working/tokenization.py\")\n",
    "\n",
    "import tokenization\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "##############################################################\n",
    "\n",
    "# 메모리 관리\n",
    "import gc\n",
    "\n",
    "# 경고메시지 지우기\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 상태바 진행상태\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Text Color\n",
    "from termcolor import colored\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09562f1",
   "metadata": {},
   "source": [
    "# 전체 Data 간단 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5698e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 Data 요약\n",
    "\n",
    "BASE_DIR = './shopee-product-matching/'\n",
    "\n",
    "# CSV 파일\n",
    "train_df = pd.read_csv(BASE_DIR + 'train.csv')\n",
    "test_df = pd.read_csv(BASE_DIR + 'test.csv')\n",
    "sample_df = pd.read_csv(BASE_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc95ffb",
   "metadata": {},
   "source": [
    "### 공통 변수 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5183af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = [512, 512]\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "N_CLASSES = len(train_df['label_group'].unique()) # 11014\n",
    "\n",
    "GET_CV = True\n",
    "\n",
    "CHECK_SUB =False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba633db0",
   "metadata": {},
   "source": [
    "## Dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c67c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    if GET_CV:\n",
    "        df = pd.read_csv(BASE_DIR + 'train.csv')\n",
    "        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "        df['matches'] = df['label_group'].map(tmp)\n",
    "        df['matches'] = df['matches'].map(lambda x: ' '.join(x))\n",
    "        \n",
    "        if CHECK_SUB:\n",
    "            df = pd.concat([df, df], axis=0)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        image_path = './shopee-product-matching/train_images/' + df['image']\n",
    "    else:\n",
    "        df = pd.read_csv(BASE_DIR + 'test.csv')\n",
    "        image_path = './shopee-product-matching/test_images/' + df['image']\n",
    "        \n",
    "    return df, image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b208549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34250,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, img_path = read_dataset()\n",
    "img_path.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cae1707",
   "metadata": {},
   "source": [
    "### <train.csv 상위 5 row data>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e8aed64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \n",
       "0                          Paper Bag Victoria Secret    249114794  \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045  \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891  \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188  \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe578694",
   "metadata": {},
   "source": [
    "## <train.csv Data 요약 내용>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c6706f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34250 entries, 0 to 34249\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   posting_id   34250 non-null  object\n",
      " 1   image        34250 non-null  object\n",
      " 2   image_phash  34250 non-null  object\n",
      " 3   title        34250 non-null  object\n",
      " 4   label_group  34250 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2302ac",
   "metadata": {},
   "source": [
    "## <train data 중 각 Column 별 Unique 개수>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45f9379d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posting_id : \u001b[34m34250\u001b[0m\n",
      "image : \u001b[34m32412\u001b[0m\n",
      "image_phash : \u001b[34m28735\u001b[0m\n",
      "title : \u001b[34m33117\u001b[0m\n",
      "label_group : \u001b[34m11014\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for col in train_df.columns:\n",
    "    print('{} : {}'.format(col, colored(len(train_df[col].unique()), 'blue')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5264240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score 함수\n",
    "def f1_score(t_true, t_pred):\n",
    "    t_true = t_true.apply(lambda x : set(x.split()))\n",
    "    t_pred = t_pred.apply(lambda x : set(x.split()))\n",
    "    \n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(t_true, t_pred)])\n",
    "    len_t_true = t_true.apply(lambda x : len(x)).values\n",
    "    len_t_pred = t_pred.apply(lambda x : len(x)).values\n",
    "    \n",
    "    F1 = 2 * intersection / (len_t_true + len_t_pred)\n",
    "    \n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3a992ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArcFace loss 생성 Class\n",
    "class ArcMarginProduct(Layer):\n",
    "    '''\n",
    "    GDis(Geodestic Distance margin) 구하는 Class\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_classes, s=30, m=0.5, easy_margin=False, ls_eps=0.0, **kwargs):\n",
    "        \n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m =tf.math.cos(m)\n",
    "        self.sin_m =tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes':self.n_classes,\n",
    "            's' : self.s,\n",
    "            'm' : self.m,\n",
    "            'ls_eps' : self.ls_eps,\n",
    "            'easy_margin' : self.easy_margin\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "        \n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer = 'glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None\n",
    "            )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        \n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "            \n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        \n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1-self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "            \n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f85b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN 이웃 구하기\n",
    "def get_neighbors(df, embeddings, KNN=50, image=True):\n",
    "    model = NearestNeighbors(n_neighbors=KNN)\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "    \n",
    "    if GET_CV:\n",
    "        if image :\n",
    "            thresholds = list(np.arange(3.0, 5.0, 0.1))\n",
    "        else:\n",
    "            thresholds = list(np.arange(15, 35, 1))\n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            predictions = []\n",
    "            for k in range(embeddings.shape[0]):\n",
    "                idx = np.where(distances[k,] < threshold)[0]\n",
    "                indc = indices[k , idx]\n",
    "                posting_ids = ' '.join(df['posting_id'].iloc[indc].values)\n",
    "                predictions.append(posting_ids)\n",
    "            df['pred_matches'] = predictions\n",
    "            df['f1'] = df_score(df['matches'], df['pred_matches'])\n",
    "            score = df['f1'].mean()\n",
    "            \n",
    "            print('Our F1 score for threshold {} is {}'.format(threshold, score))\n",
    "            scores.append(score)\n",
    "            \n",
    "        thresholds_scores = pd.DataFrame({\n",
    "            'thresholds':thresholds,\n",
    "            'scored': scores\n",
    "        })\n",
    "        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "        best_threshold = max_score['thresholds'].values[0]\n",
    "        best_score = max_score['scores'].values[0]\n",
    "        \n",
    "        print('Our best score : {} , threshold : {}'.format(best_score, best_threshold))\n",
    "        \n",
    "        del predictions, scores, indc, idx\n",
    "        \n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(embeddings.shape[0]):\n",
    "            if image:\n",
    "                idx = np.where(distances[i,]<3.6)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[i,]<20.0)[0]\n",
    "                \n",
    "            ids = indices[i, idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "        \n",
    "    else:\n",
    "        predictions = []\n",
    "        for k in tqdm(range(embeddings.shape[0])):\n",
    "            if image:\n",
    "                idx = np.where(distances[k,]<3.6)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[k,]<20.0)[0]\n",
    "            indc = indices[k, idx]\n",
    "            posting_ids =df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "            \n",
    "    del model, distances, indices, idx, ids, posting_ids\n",
    "    gc.collect()\n",
    "    \n",
    "    return df, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a44f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "image_embedding = get_image_embeddings(train_image_path)\n",
    "print(image_embedding.shape)\n",
    "\n",
    "sec = time.time() - start\n",
    "times = str(datetime.timedelta(seconds=sec)).split('.')\n",
    "print('총 실행시간 :'times[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df, image_prediction = get_neighbors(train_df, image_embedding, KNN=100, image=True)\n",
    "\n",
    "sec = time.time() - start\n",
    "times = str(datetime.timedelta(seconds=sec)).split('.')\n",
    "print(times[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d97b84",
   "metadata": {},
   "source": [
    "# #####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bc181",
   "metadata": {},
   "source": [
    "# Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195e063",
   "metadata": {},
   "source": [
    "# #####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb79f0a2",
   "metadata": {},
   "source": [
    "## Text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "219ff15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []   # ==>\n",
    "    all_masks = []    # ==>\n",
    "    all_segments = [] # ==>\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "        \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "figured-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Model 전이학습 함수\n",
    "def get_text_embeddings(df, max_len = 70):\n",
    "    embeds = []\n",
    "    module_url = \"./bert_en_uncased_L-24_H-1024_A-16_1\"\n",
    "    bert_layer = hub.KerasLayer(module_url, trainable = True)\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "    \n",
    "    text = bert_encode(df['title'].values, tokenizer, max_len = max_len)\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = 11014, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "    \n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    label = Input(shape = (), name = 'label')\n",
    "    \n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    \n",
    "    x = margin([clf_output, label])\n",
    "    output = Softmax(dtype='float32')(x)\n",
    "    \n",
    "    model = Model(inputs = [input_word_ids, input_mask, segment_ids, label], \n",
    "                  outputs = [output])\n",
    "    model.load_weights('./Bert_Baseline/Bert_123.h5')\n",
    "    \n",
    "    model = Model(inputs = model.input[0:3], outputs = model.layers[-4].output)\n",
    "    \n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        text_chunk = ((text[0][a:b], text[1][a:b], text[2][a:b]))\n",
    "        text_embeddings = model.predict(text_chunk, batch_size = BATCH_SIZE)\n",
    "        embeds.append(text_embeddings)\n",
    "        \n",
    "    del model\n",
    "    \n",
    "    text_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our text embeddings shape is {text_embeddings.shape}')\n",
    "    \n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    \n",
    "    return text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1185350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7fb43b558ed0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7fb43b558ed0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# text embedding data\n",
    "\n",
    "df, img_paths = read_dataset()\n",
    "\n",
    "text_embeddings = get_text_embeddings(df)\n",
    "\n",
    "print(text_embeddings.shape)\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cnn_env] *",
   "language": "python",
   "name": "conda-env-cnn_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
